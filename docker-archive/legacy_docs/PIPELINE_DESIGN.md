
# üß± PIPELINE_DESIGN.md

## üéØ Objetivo
Este documento descreve detalhadamente o desenho funcional do pipeline de dados da infraestrutura WRMELO, do ponto de entrada (dados brutos) at√© o treinamento de modelos e deploy de resultados.

---

## üîÇ Fluxo Geral do Pipeline

```
Google Drive ‚Üí Local (Jupyter Container) 
‚Üí MinIO (Object Storage) + PostgreSQL (Invent√°rio)
‚Üí Staging ‚Üí Curadoria ‚Üí Datasets ‚Üí Colab (GPU)
‚Üí Modelagem ‚Üí Deploy ‚Üí Outputs
```

---

## 1Ô∏è‚É£ Captura de Dados

- **Origem:** Google Drive (usu√°rio ou integra√ß√£o)
- **Destino inicial:** Container `eda_jupyter-cpu` ‚Üí `/workspace/eda/raw-data/`
- **Ferramentas:** `00_capture_drive.ipynb`, `pydrive`

---

## 2Ô∏è‚É£ Ingest√£o RAW

- Verifica√ß√£o de unicidade (via checksum)
- Registro no PostgreSQL: `inventario_dados`
- Armazenamento no MinIO: `raw-data/projeto_x/`

---

## 3Ô∏è‚É£ Staging

- Processamento inicial, limpeza, padroniza√ß√£o
- Salvamento em:
  - PostgreSQL: `staging_inventario`
  - MinIO: `staging-data/projeto_x/`

---

## 4Ô∏è‚É£ Curadoria

- Engenharia de vari√°veis, transforma√ß√µes finais
- Registro em:
  - PostgreSQL: `curated_inventario`
  - MinIO: `curated-data/projeto_x/`

---

## 5Ô∏è‚É£ Gera√ß√£o de Datasets

- Separa√ß√£o em `train`, `test`, `validation`
- Exporta√ß√£o para Colab (Google Drive) e MinIO
- Registro em: `datasets_inventario`

---

## 6Ô∏è‚É£ Modelagem no Colab (T4)

- Acesso aos dados via Google Drive
- Execu√ß√£o com GPU para ML/DL/RL/NLP
- Armazenamento de modelos em Drive e/ou MinIO

---

## 7Ô∏è‚É£ Deploy e Outputs

- Upload dos modelos para MinIO: `models/projeto_x/`
- Resultados e m√©tricas salvos como `outputs/`
- APIs publicadas se necess√°rio

---

## üîÅ Ciclos Iterativos

- Todo notebook e script modificado gera commit.
- Cada etapa do pipeline √© acompanhada por metadados e logs.
