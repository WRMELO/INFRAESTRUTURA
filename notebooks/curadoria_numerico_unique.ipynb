{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a2ce89e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44dfad113b954201ba190ba376bb3d56",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Dropdown(description='Projeto:', options=('FDL',), value='FDL'), Button(button_style='primary',‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ===============================================\n",
    "# üß† Curadoria Num√©rica ‚Äì Etapa de Sele√ß√£o de Projeto\n",
    "# ===============================================\n",
    "\n",
    "from minio import Minio\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "# Conex√£o com MinIO\n",
    "minio_client = Minio(\n",
    "    \"minio:9000\",\n",
    "    access_key=\"admin\",\n",
    "    secret_key=\"senhasegura\",\n",
    "    secure=False\n",
    ")\n",
    "\n",
    "bucket_origem = \"storage-unique\"\n",
    "extensoes_validas = [\".csv\", \".xlsx\", \".xls\", \".parquet\"]\n",
    "\n",
    "# Obter prefixos de projeto\n",
    "objetos = list(minio_client.list_objects(bucket_origem, recursive=True))\n",
    "prefixos_disponiveis = sorted(set(obj.object_name.split(\"/\")[0] for obj in objetos if \"/\" in obj.object_name))\n",
    "\n",
    "prefix_dropdown = widgets.Dropdown(options=prefixos_disponiveis, description=\"Projeto:\")\n",
    "run_button = widgets.Button(description=\"üîç Buscar Arquivos\", button_style=\"primary\")\n",
    "output = widgets.Output()\n",
    "\n",
    "def listar_arquivos(btn):\n",
    "    with output:\n",
    "        clear_output()\n",
    "        prefix = prefix_dropdown.value\n",
    "        print(f\"üîé Listando arquivos com prefixo '{prefix}' no bucket '{bucket_origem}'...\")\n",
    "        arquivos_validos = [\n",
    "            obj.object_name for obj in objetos\n",
    "            if obj.object_name.startswith(prefix + \"/\") and any(obj.object_name.endswith(ext) for ext in extensoes_validas)\n",
    "        ]\n",
    "        if not arquivos_validos:\n",
    "            print(\"‚ö†Ô∏è Nenhum arquivo num√©rico v√°lido encontrado.\")\n",
    "        else:\n",
    "            print(f\"‚úÖ {len(arquivos_validos)} arquivos encontrados:\")\n",
    "            for arq in arquivos_validos:\n",
    "                print(f\"‚Ä¢ {arq}\")\n",
    "\n",
    "run_button.on_click(listar_arquivos)\n",
    "display(widgets.VBox([prefix_dropdown, run_button, output]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "28604c65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# üì° Conectar ao MinIO\n",
    "# ========================================\n",
    "\n",
    "from minio import Minio\n",
    "\n",
    "minio_client = Minio(\n",
    "    \"minio:9000\",\n",
    "    access_key=\"admin\",\n",
    "    secret_key=\"senhasegura\",\n",
    "    secure=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "83584efa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üì• Iniciando curadoria leve de 8 arquivos...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c055a6139a7402ab7fa69284b9d098f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "üîç Curadoria leve:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ Curadoria leve finalizada.\n",
      "‚úîÔ∏è 8 arquivos aprovados.\n",
      "‚ö†Ô∏è 0 arquivos rejeitados.\n"
     ]
    }
   ],
   "source": [
    "# ===============================================\n",
    "# üß† Curadoria Leve Num√©rica ‚Äì Vers√£o Corrigida (com Path)\n",
    "# ===============================================\n",
    "\n",
    "import os\n",
    "import io\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "from datetime import datetime\n",
    "from pathlib import Path  # ‚úÖ CORRE√á√ÉO: importa√ß√£o necess√°ria\n",
    "from sqlalchemy import create_engine, MetaData, Table\n",
    "\n",
    "# Conex√£o com o PostgreSQL\n",
    "engine = create_engine(\"postgresql+psycopg2://postgres:senhasegura@database-services:5432/postgres\")\n",
    "\n",
    "# Refletir tabela staging_audit_teste\n",
    "metadata = MetaData()\n",
    "metadata.reflect(bind=engine)\n",
    "staging_table = Table(\"staging_audit_teste\", metadata, autoload_with=engine)\n",
    "\n",
    "# Configurar bucket de destino\n",
    "bucket_destino = \"staging-unique\"\n",
    "if not minio_client.bucket_exists(bucket_destino):\n",
    "    minio_client.make_bucket(bucket_destino)\n",
    "\n",
    "# Recuperar arquivos v√°lidos do projeto selecionado\n",
    "prefix = prefix_dropdown.value\n",
    "arquivos_validos = [\n",
    "    obj.object_name for obj in objetos\n",
    "    if obj.object_name.startswith(prefix + \"/\") and any(obj.object_name.endswith(ext) for ext in extensoes_validas)\n",
    "]\n",
    "\n",
    "print(f\"üì• Iniciando curadoria leve de {len(arquivos_validos)} arquivos...\")\n",
    "\n",
    "aprovados = 0\n",
    "rejeitados = 0\n",
    "\n",
    "for caminho in tqdm(arquivos_validos, desc=\"üîç Curadoria leve\"):\n",
    "    try:\n",
    "        data = minio_client.get_object(bucket_origem, caminho).read()\n",
    "        ext = Path(caminho).suffix.lower()\n",
    "\n",
    "        # Leitura com fallback\n",
    "        if ext == \".csv\":\n",
    "            try:\n",
    "                df = pd.read_csv(io.BytesIO(data), sep=\",\")\n",
    "            except Exception:\n",
    "                df = pd.read_csv(io.BytesIO(data), sep=\";\")\n",
    "        elif ext in [\".xls\", \".xlsx\"]:\n",
    "            df = pd.read_excel(io.BytesIO(data))\n",
    "        elif ext == \".parquet\":\n",
    "            df = pd.read_parquet(io.BytesIO(data))\n",
    "        else:\n",
    "            raise ValueError(\"Extens√£o n√£o suportada\")\n",
    "\n",
    "        # Verifica√ß√µes m√≠nimas\n",
    "        if df.empty or df.shape[1] < 2:\n",
    "            raise ValueError(\"DataFrame vazio ou com colunas insuficientes\")\n",
    "\n",
    "        # Upload para staging-unique\n",
    "        minio_client.put_object(\n",
    "            bucket_name=bucket_destino,\n",
    "            object_name=caminho,\n",
    "            data=io.BytesIO(data),\n",
    "            length=len(data),\n",
    "            content_type=\"application/octet-stream\"\n",
    "        )\n",
    "\n",
    "        # Auditoria\n",
    "        audit = {\n",
    "            \"prefix\": prefix,\n",
    "            \"filename\": os.path.basename(caminho),\n",
    "            \"file_ext\": ext,\n",
    "            \"bucket_origin\": bucket_origem,\n",
    "            \"bucket_destino\": bucket_destino,\n",
    "            \"full_path\": f\"{bucket_destino}/{caminho}\",\n",
    "            \"source_path\": f\"{bucket_origem}/{caminho}\",\n",
    "            \"curation_type\": \"numerico\",\n",
    "            \"curation_status\": \"processed\",\n",
    "            \"timestamp\": datetime.now()\n",
    "        }\n",
    "\n",
    "        with engine.begin() as conn:\n",
    "            conn.execute(staging_table.insert().values(audit))\n",
    "\n",
    "        aprovados += 1\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Erro ao processar {caminho}: {e}\")\n",
    "        rejeitados += 1\n",
    "\n",
    "print(f\"\\n‚úÖ Curadoria leve finalizada.\")\n",
    "print(f\"‚úîÔ∏è {aprovados} arquivos aprovados.\")\n",
    "print(f\"‚ö†Ô∏è {rejeitados} arquivos rejeitados.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "20bc3395",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "958e6cc018c449b8ad5d6d58127d6a97",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(description='Curadoria:', layout=Layout(width='60%'), options=('Machine Learning', 'Deep Learning', '‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ===============================================\n",
    "# üß† Widget ‚Äì Curadoria Pesada Num√©rica (somente tipos v√°lidos para dados num√©ricos)\n",
    "# ===============================================\n",
    "\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "\n",
    "# Lista filtrada apenas para curadorias aplic√°veis a dados num√©ricos\n",
    "tipos_analise_numericos = [\n",
    "    \"Machine Learning\",\n",
    "    \"Deep Learning\",\n",
    "    \"Reinforcement Learning\",\n",
    "    \"Business Intelligence\",\n",
    "    \"An√°lise Estat√≠stica\",\n",
    "    \"Explora√ß√£o de Dados\",\n",
    "    \"S√©ries Temporais\"\n",
    "]\n",
    "\n",
    "# Dropdown para o usu√°rio escolher o tipo de curadoria pesada\n",
    "tipo_analise_selector = widgets.Dropdown(\n",
    "    options=tipos_analise_numericos,\n",
    "    description=\"Curadoria:\",\n",
    "    layout=widgets.Layout(width=\"60%\")\n",
    ")\n",
    "\n",
    "display(tipo_analise_selector)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7ce0e539",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "651711c2497c48dc86778ab03756459a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "üîé Diagn√≥stico t√©cnico:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìå Estat√≠sticas gerais extra√≠das:\n",
      " - Total de arquivos analisados: 8\n",
      " - M√©dia de linhas por arquivo: 2983\n",
      " - M√©dia de colunas totais: 20\n",
      " - M√©dia de colunas num√©ricas: 19\n",
      " - M√©dia de colunas categ√≥ricas: 1\n",
      " - M√©dia de colunas booleanas: 0\n",
      " - Presen√ßa de colunas datetime reais: N√£o\n",
      " - % m√©dio de valores ausentes: 0.0%\n",
      " - Colunas categ√≥ricas detectadas: ['Date']\n",
      " - Nenhuma coluna booleana detectada\n",
      " üïí Poss√≠vel(s) coluna(s) categ√≥rica(s) com formato datetime:\n",
      "    - 'Date' ‚Üí convers√£o bem-sucedida em 100.0% dos casos\n",
      "\n",
      "üéØ Recomenda√ß√µes autom√°ticas para curadoria de: Deep Learning\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c1b6e8986ae467c80d4f1095d7c145a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ToggleButtons(description='Normalizar num√©ricos:', options=('Sim', 'N√£o'), value='Sim')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "379d9864d99d4c31841f1dd8d9d7717c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ToggleButtons(description='Transformar categ√≥ricos:', index=1, options=('Sim', 'N√£o'), value='N√£o')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba7856c9d3fd481b9edfa0b5881c268a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ToggleButtons(description='Remover categ√≥ricos:', options=('Sim', 'N√£o'), value='Sim')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0da5082531294a24adda1794f32d85fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ToggleButtons(description='Tratar valores nulos:', options=('Sim', 'N√£o'), value='Sim')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1d7ee6024f646dc86cdafcbee3e104c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ToggleButtons(description='Converter booleanos:', options=('Sim', 'N√£o'), value='Sim')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe9875932e314a8084e19d42f398aa7f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ToggleButtons(description='Extrair de datas:', options=('Sim', 'N√£o'), value='Sim')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd72c2256a124521af91d9280b49c881",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatSlider(value=0.0, description='% M√°x Nulos:', layout=Layout(width='50%'), max=1.0, readout_format='.0%', ‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4af386beae864ec48fb783a674903c58",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(button_style='success', description='üíæ Confirmar Par√¢metros', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4ea17dd2e034b4d88a8adfded0d4bcf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import io\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from tqdm.notebook import tqdm\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "\n",
    "# --- Fun√ß√£o auxiliar para detectar datas impl√≠citas em colunas categ√≥ricas ---\n",
    "def detectar_colunas_datetime(df, threshold=0.8):\n",
    "    candidatas = df.select_dtypes(include=\"object\").columns\n",
    "    colunas_convertiveis = []\n",
    "    for col in candidatas:\n",
    "        try:\n",
    "            convertidos = pd.to_datetime(df[col], errors=\"coerce\")\n",
    "            taxa_sucesso = convertidos.notna().mean()\n",
    "            if taxa_sucesso >= threshold:\n",
    "                colunas_convertiveis.append((col, round(taxa_sucesso * 100, 1)))\n",
    "        except Exception:\n",
    "            continue\n",
    "    return colunas_convertiveis\n",
    "\n",
    "# --- Configura√ß√µes ---\n",
    "bucket_origem = \"staging-unique\"\n",
    "prefix = prefix_dropdown.value\n",
    "tipo_analise = tipo_analise_selector.value\n",
    "extensoes_validas = [\".csv\", \".xls\", \".xlsx\", \".parquet\"]\n",
    "\n",
    "objetos = list(minio_client.list_objects(bucket_origem, recursive=True))\n",
    "arquivos_validos = [\n",
    "    obj.object_name for obj in objetos\n",
    "    if obj.object_name.startswith(prefix + \"/\") and any(obj.object_name.endswith(ext) for ext in extensoes_validas)\n",
    "]\n",
    "\n",
    "estatisticas = []\n",
    "primeiras_colunas_cat = []\n",
    "primeiras_colunas_bool = []\n",
    "colunas_datetime_implicitas = []\n",
    "\n",
    "for caminho in tqdm(arquivos_validos[:100], desc=\"üîé Diagn√≥stico t√©cnico\"):\n",
    "    try:\n",
    "        raw_data = minio_client.get_object(bucket_origem, caminho).read()\n",
    "        ext = Path(caminho).suffix.lower()\n",
    "\n",
    "        if ext == \".csv\":\n",
    "            try:\n",
    "                df = pd.read_csv(io.BytesIO(raw_data), sep=\",\")\n",
    "            except:\n",
    "                df = pd.read_csv(io.BytesIO(raw_data), sep=\";\")\n",
    "        elif ext in [\".xls\", \".xlsx\"]:\n",
    "            df = pd.read_excel(io.BytesIO(raw_data))\n",
    "        elif ext == \".parquet\":\n",
    "            df = pd.read_parquet(io.BytesIO(raw_data))\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "        tipos = df.dtypes\n",
    "        n_linhas, n_colunas = df.shape\n",
    "        num_cols = tipos[tipos.apply(lambda x: np.issubdtype(x, np.number))].shape[0]\n",
    "        cat_cols = tipos[tipos == \"object\"].shape[0]\n",
    "        bool_cols = tipos[tipos == \"bool\"].shape[0]\n",
    "        dt_cols = tipos[tipos.apply(lambda x: np.issubdtype(x, np.datetime64))].shape[0]\n",
    "        std_medio = df.select_dtypes(include=\"number\").std().mean()\n",
    "        missing_pct = df.isnull().mean().mean()\n",
    "\n",
    "        if not primeiras_colunas_cat and cat_cols > 0:\n",
    "            primeiras_colunas_cat = df.select_dtypes(include=\"object\").columns.tolist()\n",
    "        if not primeiras_colunas_bool and bool_cols > 0:\n",
    "            primeiras_colunas_bool = df.select_dtypes(include=\"bool\").columns.tolist()\n",
    "        if not colunas_datetime_implicitas:\n",
    "            colunas_datetime_implicitas = detectar_colunas_datetime(df)\n",
    "\n",
    "        estatisticas.append({\n",
    "            \"arquivo\": caminho,\n",
    "            \"linhas\": n_linhas,\n",
    "            \"colunas\": n_colunas,\n",
    "            \"col_num\": num_cols,\n",
    "            \"col_cat\": cat_cols,\n",
    "            \"col_bool\": bool_cols,\n",
    "            \"col_data\": dt_cols,\n",
    "            \"std_medio\": round(std_medio, 3) if not np.isnan(std_medio) else 0,\n",
    "            \"missing_pct\": round(missing_pct, 3),\n",
    "        })\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Erro ao processar {caminho}: {e}\")\n",
    "\n",
    "df_diag = pd.DataFrame(estatisticas)\n",
    "\n",
    "# --- Exibir estat√≠sticas gerais ---\n",
    "print(\"\\nüìå Estat√≠sticas gerais extra√≠das:\")\n",
    "print(f\" - Total de arquivos analisados: {len(df_diag)}\")\n",
    "print(f\" - M√©dia de linhas por arquivo: {int(df_diag['linhas'].mean())}\")\n",
    "print(f\" - M√©dia de colunas totais: {int(df_diag['colunas'].mean())}\")\n",
    "print(f\" - M√©dia de colunas num√©ricas: {int(df_diag['col_num'].mean())}\")\n",
    "print(f\" - M√©dia de colunas categ√≥ricas: {int(df_diag['col_cat'].mean())}\")\n",
    "print(f\" - M√©dia de colunas booleanas: {int(df_diag['col_bool'].mean())}\")\n",
    "print(f\" - Presen√ßa de colunas datetime reais: {'Sim' if df_diag['col_data'].sum() > 0 else 'N√£o'}\")\n",
    "print(f\" - % m√©dio de valores ausentes: {df_diag['missing_pct'].mean():.1%}\")\n",
    "\n",
    "if primeiras_colunas_cat:\n",
    "    print(f\" - Colunas categ√≥ricas detectadas: {primeiras_colunas_cat}\")\n",
    "else:\n",
    "    print(\" - Nenhuma coluna categ√≥rica detectada\")\n",
    "\n",
    "if primeiras_colunas_bool:\n",
    "    print(f\" - Colunas booleanas detectadas: {primeiras_colunas_bool}\")\n",
    "else:\n",
    "    print(\" - Nenhuma coluna booleana detectada\")\n",
    "\n",
    "if colunas_datetime_implicitas:\n",
    "    print(f\" üïí Poss√≠vel(s) coluna(s) categ√≥rica(s) com formato datetime:\")\n",
    "    for col, pct in colunas_datetime_implicitas:\n",
    "        print(f\"    - '{col}' ‚Üí convers√£o bem-sucedida em {pct}% dos casos\")\n",
    "else:\n",
    "    print(\" - Nenhuma coluna categ√≥rica com formato de data foi identificada\")\n",
    "\n",
    "print(f\"\\nüéØ Recomenda√ß√µes autom√°ticas para curadoria de: {tipo_analise}\")\n",
    "\n",
    "# --- Sugest√µes autom√°ticas ---\n",
    "sugestoes = {\n",
    "    \"normalizar\": tipo_analise in [\"Machine Learning\", \"Deep Learning\", \"Reinforcement Learning\", \"S√©ries Temporais\"],\n",
    "    \"transformar_cat\": tipo_analise in [\"Machine Learning\", \"Reinforcement Learning\"],\n",
    "    \"remover_cat\": tipo_analise in [\"Deep Learning\"],\n",
    "    \"tratar_nulos\": True,\n",
    "    \"converter_bool\": True,\n",
    "    \"extrair_tempo\": tipo_analise in [\"S√©ries Temporais\", \"Business Intelligence\"] or bool(colunas_datetime_implicitas)\n",
    "}\n",
    "\n",
    "# --- Controles interativos ---\n",
    "toggle_normalizar = widgets.ToggleButtons(options=[\"Sim\", \"N√£o\"],\n",
    "    value=\"Sim\" if sugestoes[\"normalizar\"] else \"N√£o\", description=\"Normalizar num√©ricos:\")\n",
    "toggle_transformar_cat = widgets.ToggleButtons(options=[\"Sim\", \"N√£o\"],\n",
    "    value=\"Sim\" if sugestoes[\"transformar_cat\"] else \"N√£o\", description=\"Transformar categ√≥ricos:\")\n",
    "toggle_remover_cat = widgets.ToggleButtons(options=[\"Sim\", \"N√£o\"],\n",
    "    value=\"Sim\" if sugestoes[\"remover_cat\"] else \"N√£o\", description=\"Remover categ√≥ricos:\")\n",
    "toggle_tratar_nulos = widgets.ToggleButtons(options=[\"Sim\", \"N√£o\"],\n",
    "    value=\"Sim\", description=\"Tratar valores nulos:\")\n",
    "toggle_converter_bool = widgets.ToggleButtons(options=[\"Sim\", \"N√£o\"],\n",
    "    value=\"Sim\", description=\"Converter booleanos:\")\n",
    "toggle_extrair_tempo = widgets.ToggleButtons(options=[\"Sim\", \"N√£o\"],\n",
    "    value=\"Sim\" if sugestoes[\"extrair_tempo\"] else \"N√£o\", description=\"Extrair de datas:\")\n",
    "\n",
    "slider_missing = widgets.FloatSlider(\n",
    "    value=float(np.percentile(df_diag[\"missing_pct\"], 90)),\n",
    "    min=0.0, max=1.0, step=0.01,\n",
    "    description=\"% M√°x Nulos:\", readout_format=\".0%\",\n",
    "    style={'description_width': 'initial'}, layout=widgets.Layout(width='50%')\n",
    ")\n",
    "\n",
    "# --- Exibi√ß√£o dos controles ---\n",
    "display(toggle_normalizar, toggle_transformar_cat, toggle_remover_cat,\n",
    "        toggle_tratar_nulos, toggle_converter_bool, toggle_extrair_tempo, slider_missing)\n",
    "\n",
    "# --- Bot√£o de confirma√ß√£o que imprime no output ---\n",
    "def consolidar_opcoes(_):\n",
    "    crit_params = {\n",
    "        \"normalizar\": toggle_normalizar.value == \"Sim\",\n",
    "        \"transformar_cat\": toggle_transformar_cat.value == \"Sim\",\n",
    "        \"remover_cat\": toggle_remover_cat.value == \"Sim\",\n",
    "        \"tratar_nulos\": toggle_tratar_nulos.value == \"Sim\",\n",
    "        \"converter_bool\": toggle_converter_bool.value == \"Sim\",\n",
    "        \"extrair_tempo\": toggle_extrair_tempo.value == \"Sim\",\n",
    "        \"min_cols\": int(np.percentile(df_diag[\"colunas\"], 10)),\n",
    "        \"max_missing_pct\": slider_missing.value\n",
    "    }\n",
    "    globals()[\"crit_params\"] = crit_params\n",
    "    out = widgets.Output()\n",
    "    with out:\n",
    "        print(\"‚úÖ Par√¢metros definidos e prontos para a curadoria pesada:\\n\")\n",
    "        print(json.dumps(crit_params, indent=4))\n",
    "    display(out)\n",
    "\n",
    "botao_confirmar = widgets.Button(description=\"üíæ Confirmar Par√¢metros\", button_style=\"success\")\n",
    "botao_confirmar.on_click(consolidar_opcoes)\n",
    "display(botao_confirmar)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f8352ffa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bfed112d10a1429c88aae32b9c8a6c8d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Curando arquivos num√©ricos...:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ 8 arquivos curados e enviados com sucesso.\n"
     ]
    }
   ],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "from datetime import datetime\n",
    "from sqlalchemy import MetaData, insert\n",
    "from os.path import basename, splitext\n",
    "from io import BytesIO\n",
    "import pandas as pd\n",
    "\n",
    "def sqlalchemy_table(nome):\n",
    "    metadata = MetaData()\n",
    "    metadata.reflect(bind=engine)\n",
    "    return metadata.tables[nome]\n",
    "\n",
    "bucket_origem = \"staging-unique\"\n",
    "bucket_destino = \"curated-unique\"\n",
    "tabela = sqlalchemy_table(\"curation_audit\")\n",
    "curation_type = f\"numerical-{tipo_analise.lower().replace(' ', '_')}\"\n",
    "arquivos = [obj.object_name for obj in minio_client.list_objects(bucket_origem, recursive=True) if obj.object_name.endswith(\".csv\")]\n",
    "processados = 0\n",
    "\n",
    "for caminho in tqdm(arquivos, desc=\"Curando arquivos num√©ricos...\"):\n",
    "    try:\n",
    "        response = minio_client.get_object(bucket_origem, caminho)\n",
    "        df = pd.read_csv(response)\n",
    "        transformacoes = []\n",
    "\n",
    "        if df.isnull().any().any():\n",
    "            df = df.dropna(axis=1, thresh=int((1 - max_missing_pct) * len(df)))\n",
    "            transformacoes.append(\"‚úîÔ∏è nulos tratados\")\n",
    "\n",
    "        bool_cols = df.select_dtypes(include=\"bool\").columns.tolist()\n",
    "        if bool_cols:\n",
    "            df[bool_cols] = df[bool_cols].astype(int)\n",
    "            transformacoes.append(\"‚úîÔ∏è booleanos convertidos\")\n",
    "\n",
    "        cat_cols = df.select_dtypes(include=\"object\").columns.tolist()\n",
    "        if cat_cols:\n",
    "            df = df.drop(columns=cat_cols)\n",
    "            transformacoes.append(\"‚úîÔ∏è categ√≥ricas removidas\")\n",
    "\n",
    "        date_cols = [col for col in df.columns if \"date\" in col.lower() or \"data\" in col.lower()]\n",
    "        for col in date_cols:\n",
    "            df[col] = pd.to_datetime(df[col], errors='coerce')\n",
    "            df[f\"{col}_year\"] = df[col].dt.year\n",
    "            df[f\"{col}_month\"] = df[col].dt.month\n",
    "            df[f\"{col}_day\"] = df[col].dt.day\n",
    "            df.drop(columns=[col], inplace=True)\n",
    "            transformacoes.append(\"‚úîÔ∏è datas decompostas\")\n",
    "\n",
    "        df = (df - df.mean()) / df.std()\n",
    "        transformacoes.append(\"‚úîÔ∏è normaliza√ß√£o aplicada\")\n",
    "\n",
    "        buffer = BytesIO()\n",
    "        df.to_parquet(buffer, index=False)\n",
    "        buffer.seek(0)\n",
    "\n",
    "        novo_nome = splitext(caminho)[0] + \".parquet\"\n",
    "        minio_client.put_object(bucket_destino, novo_nome, buffer, length=buffer.getbuffer().nbytes, content_type=\"application/parquet\")\n",
    "\n",
    "        with engine.begin() as conn:\n",
    "            conn.execute(insert(tabela), {\n",
    "                \"prefix\": prefix,\n",
    "                \"full_path\": novo_nome,\n",
    "                \"filename\": basename(novo_nome),\n",
    "                \"file_ext\": \".parquet\",\n",
    "                \"curation_type\": curation_type,\n",
    "                \"curation_details\": \"; \".join(transformacoes),\n",
    "                \"timestamp\": datetime.utcnow(),\n",
    "                \"source_path\": caminho,\n",
    "                \"bucket_origin\": bucket_origem,\n",
    "                \"bucket_curated\": bucket_destino,\n",
    "                \"curation_status\": \"processed\"\n",
    "            })\n",
    "\n",
    "        processados += 1\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Erro em {caminho}: {str(e)}\")\n",
    "\n",
    "print(f\"‚úÖ {processados} arquivos curados e enviados com sucesso.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5e3e9c1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üì• Arquivos num√©ricos em 'staging-unique': 8\n",
      "üì§ Arquivos .parquet em 'curated-unique': 8\n",
      "üìù Arquivos .parquet registrados no audit: 10\n"
     ]
    }
   ],
   "source": [
    "from sqlalchemy import text\n",
    "\n",
    "# üì• Arquivos CSV em staging\n",
    "csv_staging = [\n",
    "    obj.object_name for obj in minio_client.list_objects(\"staging-unique\", recursive=True)\n",
    "    if obj.object_name.endswith(\".csv\")\n",
    "]\n",
    "\n",
    "# üì§ Arquivos Parquet em curated\n",
    "parquet_curated = [\n",
    "    obj.object_name for obj in minio_client.list_objects(\"curated-unique\", recursive=True)\n",
    "    if obj.object_name.endswith(\".parquet\")\n",
    "]\n",
    "\n",
    "# üìù Arquivos Parquet registrados no audit\n",
    "query = \"\"\"\n",
    "SELECT COUNT(*) FROM curation_audit\n",
    "WHERE curation_status = 'processed'\n",
    "  AND file_ext = '.parquet'\n",
    "\"\"\"\n",
    "with engine.connect() as conn:\n",
    "    parquet_audit = conn.execute(text(query)).scalar()\n",
    "\n",
    "# üìä Resultado\n",
    "print(f\"üì• Arquivos num√©ricos em 'staging-unique': {len(csv_staging)}\")\n",
    "print(f\"üì§ Arquivos .parquet em 'curated-unique': {len(parquet_curated)}\")\n",
    "print(f\"üìù Arquivos .parquet registrados no audit: {parquet_audit}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "77111034",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìù 10 arquivos .parquet registrados no audit:\n",
      "\n",
      " - FDL/BBAS3.SA/teste.parquet\n",
      " - FDL/BBAS3.SA/teste.parquet\n",
      " - FDL/BBAS3.SA/treino.parquet\n",
      " - FDL/BBAS3.SA/treino.parquet\n",
      " - FDL/CSNA3.SA/teste.parquet\n",
      " - FDL/CSNA3.SA/treino.parquet\n",
      " - FDL/PETR4.SA/teste.parquet\n",
      " - FDL/PETR4.SA/treino.parquet\n",
      " - FDL/VALE3.SA/teste.parquet\n",
      " - FDL/VALE3.SA/treino.parquet\n"
     ]
    }
   ],
   "source": [
    "from sqlalchemy import text\n",
    "\n",
    "query = \"\"\"\n",
    "SELECT full_path\n",
    "FROM curation_audit\n",
    "WHERE curation_status = 'processed'\n",
    "  AND file_ext = '.parquet'\n",
    "ORDER BY full_path\n",
    "\"\"\"\n",
    "\n",
    "with engine.connect() as conn:\n",
    "    resultados = conn.execute(text(query)).fetchall()\n",
    "\n",
    "print(f\"üìù {len(resultados)} arquivos .parquet registrados no audit:\\n\")\n",
    "for row in resultados:\n",
    "    print(\" -\", row[0])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
