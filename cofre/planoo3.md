%%markdown
# ğŸ“‘ Documento TÃ©cnico â€” Pipeline-PadrÃ£o de Dados  
*VersÃ£o: 2025-05-27*

---

## 0. Prompt-Origem do Gerente de Projeto (VocÃª)

> **â€œO que estou fazendo Ã© a criaÃ§Ã£o de uma infraestrutura que me permita padronizar o mÃ¡ximo possÃ­vel a fase de staging/eda/limpeza/curadoria dos dados recebidos de diversos processos e projetos e que serÃ£o usados para RL, DL, ML, imagem, engenharia, etcâ€¦ dependendo do que for o objeto do projeto contratado.  
> [â€¦] DÃšVIDA: dados esse tipo informaÃ§Ã£o, podemos escolher os melhores (ou mais recomendados) tratamentos que o mercado usa e definirmos como nosso pipeline padrÃ£o?â€**

Esse pedido disparou a anÃ¡lise e as decisÃµes tÃ©cnicas registradas abaixo.

---

## 1. DecisÃµes TÃ©cnicas Consolidadas

| Tema | DecisÃ£o | MotivaÃ§Ã£o |
|------|---------|-----------|
| **Stack de processamento** | **pandas + Polars** (Spark fora do pipeline-padrÃ£o). | Volumes previstos \< 100 GB; Polars entrega alta performance sem complexidade de cluster. |
| **ValidaÃ§Ã£o de dados** | **Great Expectations** em contÃªiner Alpine/Python. | Projeto open-source, integra com pandas/Polars, gera relatÃ³rios HTML, atende compliance. |
| **Versionamento / Linhagem** | **DVC** com *remote* `dvc-remote` no MinIO. | MantÃ©m Git enxuto, usa hashes compatÃ­veis com `storage_audit`, reprodutibilidade simples. |
| **Formato da camada curated** | Tabular em **Parquet** (Snappy, particionado `projeto/ano=mÃªs=`).<br>Imagens em hierarquia simples no MinIO. | Parquet Ã© padrÃ£o column-store; hierarquia de imagens preserva SHA-256 no Postgres. |
| **Nulos & outliers (tabular)** | ImputaÃ§Ã£o por mediana + Winsorization (1Âº/99Âº pct).<br>CategÃ³ricos: categoria â€œmissingâ€. | EstratÃ©gia robusta, 100 % automÃ¡tica e reversÃ­vel por projeto. |
| **Reprodutibilidade** | **CLI** (`datapiper`) instalÃ¡vel via `pip install -e .` + notebooks apenas como tutoriais. | IdempotÃªncia, CI/CD amigÃ¡vel; evita divergÃªncia de lÃ³gica em notebooks. |

---

## 2. Arquitetura de Pastas & Controle de VersÃ£o

repo-root/
â”œâ”€â”€ data/ # Controlado por DVC
â”‚ â”œâ”€â”€ raw/ # Espelha recepcao-raw (MinIO)
â”‚ â”œâ”€â”€ staging/
â”‚ â”œâ”€â”€ validated/
â”‚ â””â”€â”€ curated/
â”œâ”€â”€ src/
â”‚ â””â”€â”€ datapiper/ # Pacote CLI
â”œâ”€â”€ dvc.yaml # Pipeline DVC
â””â”€â”€ notebooks/ # EDA exploratÃ³rio


### Prefixos no MinIO

storage-unique/
â””â”€â”€ curated/
â””â”€â”€ <project>/
â”œâ”€â”€ tabular/year=2025/month=05/*.parquet
â””â”€â”€ images/{train,test}/â€¦


---

## 3. Comandos-Chave do CLI `datapiper`

| Comando | AÃ§Ãµes principais | PersistÃªncia |
|---------|-----------------|--------------|
| `datapiper ingest --project X` | â€¢ Copia de `recepcao-raw` â†’ `staging/` <br>â€¢ Registra no `reception_audit` | Arquivos locais + Postgres |
| `datapiper validate --project X` | â€¢ Executa expectativas GE <br>â€¢ Move bons arquivos â†’ `validated/` | RelatÃ³rio GE + status |
| `datapiper transform --project X` | â€¢ Limpeza/FE default <br>â€¢ Gera Parquet/imagens padronizadas | `storage_audit` + MinIO |
| **Pipeline completo** | `dvc repro` | Idempotente; push/pull via DVC remote |

---

## 4. Acesso Colab â†’ MinIO (Dados Curados)

1. **PadrÃ£o oficial:** tÃºnel Cloudflare Zero-Trust â†’ URL HTTPS pÃºblica restrita.  
   ```python
   from minio import Minio
   client = Minio(
       "minio.<domÃ­nio-tÃºnel>.com",
       access_key="admin",
       secret_key="*****",
       secure=True,
   )
    lternativas:

        rclone sync para Google Drive (duplica storage).

        Mirror para bucket GCS / S3 (custo extra).

5. PrÃ³ximos Artefatos a Entregar

    pyproject.toml com entry-points datapiper-*.

    dvc.yaml inicial com as trÃªs etapas.

    Guia Cloudflare Tunnel + variÃ¡veis de ambiente Colab.

(Aguardando OK do Gerente para iniciar esses arquivos.)
6. ObservaÃ§Ãµes Gerenciais Registradas

    Spark removido por nÃ£o haver volumes > 100 GB.

    LicenÃ§as: preferir sempre cÃ³digo aberto; GE cumpre.

    DVC Remote em MinIO aprovado; MongoDB disponÃ­vel como opÃ§Ã£o futura de artefatos.

    Sem exigÃªncia de Delta Lake.

    Tratamentos default aceitÃ¡veis, mas ajustÃ¡veis por projeto.

7. Linha do Tempo de DiscussÃ£o (resumida)

    SolicitaÃ§Ã£o inicial de padronizaÃ§Ã£o de pipeline.

    Proposta de blocos reutilizÃ¡veis â†’ seis questÃµes levantadas.

    Ajuste conforme protocolo (IA decide â€œcomoâ€) â†’ decisÃµes tÃ©cnicas definidas.

    ConfirmaÃ§Ãµes gerenciais (licenÃ§a OSS, sem Spark, etc.).

    Detalhamento do fluxo CLI + Colab/MinIO.

    Este documento .md consolidado.

    %%markdown
## 8. Ajuste para Contexto de Pesquisa / P&D  
*(foco: prototipar rapidamente o melhor modelo, sem sobrecarga de â€œproduÃ§Ã£oâ€)*

### 8.1 RevisÃ£o dos Componentes

| Componente | SituaÃ§Ã£o anterior | DecisÃ£o para P&D | Racional |
|------------|------------------|------------------|----------|
| **Stack de processamento** | pandas + Polars | **Mantido** | Continuidade da produtividade e performance local; dispensa Spark. |
| **ValidaÃ§Ã£o de dados** | Great Expectations | **Opcional** â†’ trocar por **ydata-profiling** (antes pandas-profiling) | GE pode ser exagerado para pesquisa; profiling rÃ¡pido jÃ¡ sinaliza problemas. |
| **Versionamento de dados** | DVC + MinIO Remote | **Opcional** â†’ pode ser substituÃ­do por **MLflow Tracking** (artefatos) ou simples timestamp em pasta | Menos fricÃ§Ã£o durante experimentaÃ§Ã£o; MLflow jÃ¡ agrega mÃ©tricas de modelo. |
| **CLI `datapiper`** | Pipeline idempotente | **Descartado nesta fase**; usar funÃ§Ãµes utilitÃ¡rias dentro do notebook | Notebook interativo Ã© melhor no ciclo explorar-ajustar-testar. |
| **Nulos & outliers** | Mediana + Winsorization (default) | **Mantido (default)**, mas facilmente modificÃ¡vel na cÃ©lula de limpeza | EstratÃ©gia segura; ajuste livre por experimento. |
| **Arquitetura de pastas** | raw / staging / validated / curated (DVC) | **Simplificada** para `raw/` e `processed/` dentro do projeto | Menos camadas atÃ© ter modelo final. |
| **Acesso Colab â†’ MinIO** | TÃºnel Cloudflare + MinIO | **Mantido** | Ãšnico ponto realmente necessÃ¡rio para compartilhar dados sem duplicaÃ§Ã£o. |

---

### 8.2 Pipeline Minimalista Sugerido

1. **Notebook Ãºnico** por projeto:  
   - `Imports & utils` (funÃ§Ãµes em `utils.py`).  
   - **Load raw** do MinIO.  
   - **EDA / Profiling** (`ydata-profiling.ProfileReport`).  
   - **Data-Cleaning & Feature-Engineering** (pandas / Polars).  
   - **Modelagem + Tracking** (MLflow opcional).  
2. **Versionamento leve**:  
   - Commit do notebook + `requirements.txt` no Git.  
   - Artefatos de modelo/dataset, se necessÃ¡rio, via MLflow ou pasta `artifacts/2025-05-27T15-34/`.  
3. **Dados**:  
   - Permanecem em MinIO â†’ Prefixos `raw/` e `processed/`.  
   - Hashes ainda podem ir para Postgres, mas **nÃ£o bloqueiam** a execuÃ§Ã£o cientÃ­fica.

---

### 8.3 ConclusÃ£o

> **Para o ciclo de P&D, mantemos pandas + Polars e o acesso MinIO; substituÃ­mos GE / DVC / CLI por ferramentas mais leves (ydata-profiling, MLflow ou simples pasta de artefatos) e rodamos tudo diretamente no notebook.**  
> Quando (e se) o modelo precisar virar produÃ§Ã£o, reativamos o pipeline â€œrobustoâ€ previamente especificado.
